{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monotone schemes with a second order non-linearity, in two space dimensions\n",
    "\n",
    "This notebook illustrates the use of monotone finite difference schemes to compute viscosity solutions of non-linear PDEs, in two space dimensions. \n",
    "We consider the operator\n",
    "$$\n",
    "    \\Lambda u(x) := \\alpha(x) \\lambda_{\\max}(\\nabla^2 u(x)) + \\lambda_{\\min}(\\nabla^2 u(x))\n",
    "$$\n",
    "in the PDE\n",
    "$$\n",
    "    \\Lambda u(x) = \\beta(x),\n",
    "$$\n",
    "with Dirichlet boundary conditions. The PDE parameters are a positive function $\\alpha$, and an arbitrary function $\\beta$.\n",
    "We denote by $\\lambda_{\\max}(M)$ and $\\lambda_{\\min}(M)$ are the largest and smallest eigenvalue of a positive definite tensor $M$. More details on this problem below.\n",
    "\n",
    "We design a two monotone numerical schemes: \n",
    "* The first sheme, based on a discretization of the space of controls, is simple to implement. However it is quite costly numerically, and it induces a consistency defect.\n",
    "* The second scheme is second order consistent and possibly cheaper numerically. However, implementation details are more subtle.\n",
    "\n",
    "The two schemes involves adaptive stencils, built using techniques from lattice geometry. The techniques developed are fairly general, and can be applied to a wide rande of non-linear PDEs. Numerical implementation is kept simple thanks to the use of automatic differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformulation and an extremal operator\n",
    "\n",
    "Assume without loss of generality that $\\alpha \\leq 1$. Then for any positive definite matrix $M$ one has \n",
    "$$\n",
    "    \\alpha \\lambda_{\\max}(M) + \\lambda_{\\min}(M) = \\min_{0 \\leq \\theta \\leq \\pi} {\\rm tr}(D_\\alpha(\\theta) M),\n",
    "$$\n",
    "where we denoted, with $e(\\theta) := (\\cos \\theta, \\sin \\theta)$\n",
    "$$\n",
    "    D_\\alpha(\\theta) = \\alpha\\, e(\\theta) e(\\theta)^T + e(\\theta)^\\perp (e(\\theta)^\\perp)^T,\n",
    "$$\n",
    "the symmetric matrix whose eigenvalues are $\\alpha$ and $1$, the former associated with the eigenvector $e(\\theta)$.\n",
    "\n",
    "**Remark on the range of the variable $\\theta$.**\n",
    "For any $\\theta\\in \\mathbb R$, one has $e(\\theta+\\pi) = -e(\\theta)$, and therefore $D_\\alpha(\\theta+\\pi) = D_\\alpha(\\theta)$. By periodicity, one may therefore limit its attention to the interval $[0,\\pi]$.\n",
    "\n",
    "**Remark on the case $\\alpha\\geq 1$.**\n",
    "This second case is handled by replacing the minimum over $\\theta\\in [0,\\pi]$ with a maximum. This does not induce any additional difficulty from the theoretical or numerical standpoints. However, for the sake of simplicity, we make the assumption that $\\alpha\\leq 1$ in the following.\n",
    "\n",
    "### First discretization strategy (sampling of the control space)\n",
    "\n",
    "Let $K$ be a positive integer, and let $\\theta_1 \\leq \\cdots \\leq \\theta_K$ be a sampling of the interval $[0,\\pi]$. Then we may consider the approximate operator\n",
    "$$\n",
    "    \\Lambda_K u(x) := \\min_{1 \\leq k \\leq K} {\\rm tr} (D_\\alpha(\\theta_k) \\nabla^2 u(x)).\n",
    "$$\n",
    "Introduce decompositions of the tensors, obtained e.g. by Selling's method,\n",
    "$$\n",
    "    D_\\alpha(\\theta_k) = \\sum_{1 \\leq i \\leq n} \\mu_{ki} e_{ki} e_{ki}^T,\n",
    "$$\n",
    "where $\\mu_{ki} \\geq 0$ and $e_{ki}$ has integer coordinates. Then we obtain the monotone numerical scheme\n",
    "$$\n",
    "    \\min_{1 \\leq k \\leq K} \\sum_{1 \\leq i \\leq n} \\mu_{ki} \\frac{ u(x+h e_{ki}) - 2 u(x) +u(x-h e_{ki})} {h^2}.\n",
    "$$\n",
    "A consistency defect remains, which can be estimated in terms of the width of the sampling $\\theta_1,\\cdots,\\theta_K$ of the control space $[0,\\pi]$. \n",
    "\n",
    "An additional problem is that the numerical scheme cost increases as $K$ increases.\n",
    "This issue becomes more acute in the case of a multi-dimensional control space.\n",
    "\n",
    "### Second discretization (consistent implementation)\n",
    "\n",
    "In order to introduce this discretization, we need to recall some elements from lattice geometry.\n",
    "Selling's decomposition of a tensor $D$ involves a geometrical object, referred to as a *$D$-obtuse superbase* and here  denoted\n",
    "$$\n",
    "    {\\rm osb}(D).\n",
    "$$\n",
    "The obtuse superbase $s={\\rm osb}(D)$ dictates the support $(e_{si})_{i=1}^n$ of Selling's decomposition of $D$, hence the stencil of the numerical scheme. We can take advantage of this fact to rewrite the operator as \n",
    "$$\n",
    "    \\Lambda u(x) = \\min_{s \\in S} \\Lambda_s u(x)\n",
    "$$\n",
    "where \n",
    "$$\n",
    "    \\Lambda_s u(x) := \\min_{\\theta, {\\rm obs}(D_\\alpha(\\theta)) = s} {\\rm tr} (D_\\alpha(\\theta) \\nabla^2 u).\n",
    "$$\n",
    "Each operator $\\Lambda_s$ admits the consistent discretization\n",
    "$$\n",
    "    \\Lambda_s u(x) \\approx \\min_{\\theta, {\\rm obs}(D_\\alpha(\\theta)) = s} \\sum_{1 \\leq i \\leq n} \n",
    "    \\mu_{si}(\\theta) \\frac{u(x+h e_{si}) - 2 u(x) + u(x-e_{si})} {h^2}, \n",
    "$$\n",
    "and a closed form can be obtained for the r.h.s. by examining a simple optimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"..\") # Allow import from parent directory\n",
    "from NumericalSchemes import Selling\n",
    "from NumericalSchemes import LinearParallel as lp\n",
    "from NumericalSchemes import FiniteDifferences as fd\n",
    "spad = fd.spAD # Alternatively : from NumericalSchemes import SparseAutomaticDifferentiation as spad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg; import scipy.sparse; import scipy.sparse.linalg "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_field(u,shape):\n",
    "    ndim = len(shape)\n",
    "    if u.ndim>=ndim and u.shape[-ndim:]==shape: return u\n",
    "    else: return spad.broadcast_to(u.reshape(u.shape+(1,)*ndim), u.shape+shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_residue(res):\n",
    "    return - scipy.sparse.linalg.spsolve(\n",
    "        scipy.sparse.coo_matrix(res.triplets()).tocsr(),\n",
    "        res.value.flatten()).reshape(res.shape)\n",
    "\n",
    "def solve(Scheme,params,guess,print_period=1,niter=8,relax=0.):\n",
    "    u = spad.identity(guess.shape)+guess\n",
    "    for i in range(niter):\n",
    "        residue = Scheme(u,*params)\n",
    "        if (i-1)%print_period ==0  or i==niter-1:\n",
    "            print(\"Iteration :\",i,\", Residue norm :\", LInfNorm(residue.value)) # Before solve\n",
    "        u.value += solve_residue(residue + relax)\n",
    "    return u.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "fd = importlib.reload(fd)\n",
    "spad = importlib.reload(spad)\n",
    "lp = importlib.reload(lp)\n",
    "Selling = importlib.reload(Selling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sampling based discretization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
